{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0B7p4_aX-ae",
        "outputId": "eadbb896-8f28-4786-ea96-cd4a0fdc3db9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chelo\n",
            "  Downloading chelo-0.0.4-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from chelo) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from chelo) (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from chelo) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from chelo) (2.32.3)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from chelo) (1.7.4.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (from chelo) (3.1.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from chelo) (1.4.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->chelo) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle->chelo) (2025.1.31)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle->chelo) (3.4.1)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle->chelo) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle->chelo) (5.29.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle->chelo) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->chelo) (8.0.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle->chelo) (75.1.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle->chelo) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle->chelo) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle->chelo) (2.3.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle->chelo) (0.5.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl->chelo) (2.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->chelo) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->chelo) (2025.1)\n",
            "Downloading chelo-0.0.4-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: chelo\n",
            "Successfully installed chelo-0.0.4\n",
            "Configuration file '/root/.chelo/chelo.json' does not exist. Creating a new one with default settings.\n",
            "Configuration saved to '/root/.chelo/chelo.json'.\n",
            "Default configuration file '/root/.chelo/chelo.json' created.\n",
            "Downloading dataset 'ainalirham/coal-fired-power-plant-thermal-performance-dataset' into '/root/.chelo/kaggle/ainalirham_coal-fired-power-plant-thermal-performance-dataset'...\n",
            "Dataset URL: https://www.kaggle.com/datasets/ainalirham/coal-fired-power-plant-thermal-performance-dataset\n",
            "(91, 53) (91,)\n",
            "(72, 53) (72,) (19, 53) (19,)\n",
            "Training set size: 72, Test set size: 19\n",
            "min X_train & X_train_normalized:  -93.6236187087165 0.0\n",
            "max X_train & X_train_normalized:  742858200.0 1.0\n",
            "min y_train & y_train_normalized:  93.4 0.0\n",
            "max y_train & y_train_normalized:  94.0 1.0\n",
            "First 2 rows of X_train:\n",
            "[[ 8.33316999e+02  5.68108851e+02  1.43766094e+01  5.66944458e+02\n",
            "   8.44460529e+01  1.73381982e+00  2.49447593e+02  8.56106107e+02\n",
            "   1.22369017e+02  5.00374778e+00  5.66113776e+02  1.42795175e+01\n",
            "   5.66944458e+02  1.97205816e+00  1.07108400e+01  2.19991912e+00\n",
            "   1.57349038e+01 -9.34448829e+01  3.52987005e+01  4.00155737e+02\n",
            "   1.46076575e+02  4.84553566e+02  9.94064514e+04  6.48347747e+00\n",
            "   1.17750142e+01  1.11173189e+02 -2.78466212e-01  4.53137872e+02\n",
            "   4.96937858e+01  2.18911865e+01  3.50526004e+03  6.60675510e+00\n",
            "   2.19000000e+00  3.17250000e+02  3.05901582e+03  2.95575565e+03\n",
            "   4.46244220e+02  5.49504390e+02  8.12084904e+01  5.13000000e+00\n",
            "   4.78000000e+00  3.30000000e+01  3.50380000e+02 -1.95409429e+00\n",
            "   1.20622662e+02  7.23918766e+01  1.67194000e+02  7.14252768e+08\n",
            "   2.54454139e+03  2.71475663e+03  3.03050000e+02  2.80700000e+02\n",
            "   4.27200000e+03]\n",
            " [ 8.17297928e+02  5.67950442e+02  1.40065746e+01  5.65511533e+02\n",
            "   7.46754265e+01  2.22200238e+00  2.48289007e+02  8.38621544e+02\n",
            "   1.25707637e+02  4.96466849e+00  5.66029639e+02  1.39111501e+01\n",
            "   5.65511533e+02  1.93286941e+00  1.05237091e+01  2.15744175e+00\n",
            "   1.53873208e+01 -9.31791721e+01  3.61233847e+01  4.63097633e+02\n",
            "   1.55110326e+02  4.53481143e+02  9.71316376e+04  6.64800600e+00\n",
            "   1.15567026e+01  8.77788905e+01 -2.22198046e-01  4.44736587e+02\n",
            "   4.97039757e+01  3.02158779e+01  3.50844350e+03  6.62160408e+00\n",
            "   2.16000000e+00  3.17730000e+02  3.06089711e+03  2.96063957e+03\n",
            "   4.47546393e+02  5.47803925e+02  8.16982815e+01  4.92000000e+00\n",
            "   4.82000000e+00  3.30000000e+01  3.61150000e+02 -5.59701493e-01\n",
            "   1.25188751e+02  7.19065211e+01  1.64498000e+02  7.02735456e+08\n",
            "   2.51291062e+03  2.68473357e+03  2.94970000e+02  2.79650000e+02\n",
            "   4.27200000e+03]]\n",
            "First 2 rows of normalized X_train:\n",
            "[[0.55678318 0.67032233 0.51414386 0.8606737  0.49253243 0.21629158\n",
            "  0.96336173 0.72241423 0.44175348 0.87526889 0.72605825 0.50986889\n",
            "  0.8606737  0.56542665 0.6985812  0.55588436 0.53338666 0.11869696\n",
            "  0.29353587 0.30785382 0.044446   0.98846408 0.8893739  0.41994876\n",
            "  0.45918455 0.93313429 0.12100394 0.45918455 0.66979084 0.54131572\n",
            "  0.5259753  0.47884725 0.5        0.17424242 0.25445764 0.54417008\n",
            "  0.67797125 0.73323009 0.68587947 0.90697674 0.03252033 0.75\n",
            "  0.39602597 0.         0.10469558 0.92545064 0.48716091 0.47474009\n",
            "  0.4964528  0.48899225 0.74005891 0.37685185 0.87692308]\n",
            " [0.13953627 0.62894223 0.12389992 0.48002227 0.30921504 0.27739937\n",
            "  0.90886504 0.45537522 0.68695157 0.83132248 0.7045262  0.12251788\n",
            "  0.48002227 0.13899029 0.42880141 0.13346996 0.2005862  0.2951532\n",
            "  0.7961358  0.50139641 0.12453704 0.92594245 0.51473425 0.68626655\n",
            "  0.24611828 0.25414504 0.75756251 0.24611828 0.83175657 0.78320081\n",
            "  0.73625678 0.83522683 0.2        0.26515152 0.39403331 0.84403966\n",
            "  0.7700452  0.54742202 0.8835612  0.72383721 0.09756098 0.75\n",
            "  0.81979146 0.21099133 0.43927845 0.80169953 0.27014409 0.2632564\n",
            "  0.34614687 0.35108324 0.14506627 0.27962963 0.87692308]]\n",
            "First 5 values of y_train:\n",
            "[93.73 93.6  93.55 93.76 93.69]\n",
            "First 5 values of normalized y_train:\n",
            "[0.55       0.33333333 0.25       0.6        0.48333333]\n",
            "(72, 53) (72,) (19, 53) (19,)\n",
            "Training set size: 72, Test set size: 19\n",
            "(72, 53) (72,) (19, 53) (19,)\n",
            "Training set size: 72, Test set size: 19\n",
            "Linear Regression Train MSE: 0.0000\n",
            "Linear Regression Train R2: 1.0000\n",
            "Linear Regression Train MAE: 0.0004\n",
            "Linear Regression Train MAPE: 0.0000\n",
            "\n",
            "Test Set Performance (Original Scale):\n",
            "Test MSE: 0.0000\n",
            "Test R²: 0.9995\n",
            "Test MAE: 0.0014\n",
            "Test MAPE: 0.0000\n",
            "Available features:  ['Main steam flow (t/h)', 'Main steam temperature (boiler side) (℃)', 'Main steam pressure (boiler side) (Mpa)', 'Reheat steam temperature (boiler side) (℃)', 'Superheater desuperheating water flow (t/h)', 'Reheater desuperheating water flow (t/h)', 'Feedwater temperature (℃)', 'Feedwater flow (t/h)', 'Flue gas temperature (℃)', 'Boiler oxygen level (%)', 'Main steam temperature (turbine side) (℃)', 'Main steam pressure (turbine side) (MPa)', 'Reheat steam temperature (turbine side) (℃)', 'Reheat steam pressure (turbine side) (MPa)', 'Control stage pressure (Mpa)', 'High exhaust pressure (Mpa)', 'Feedwater pressure (MPa)', 'Condenser vacuum (kPa)', 'Circulating water outlet temperature (℃)', 'SO2 (mg/m3)', 'Nox (mg/m3)', 'CO (mg/m3)', 'CO2 (ppm)', 'O2 (%)', 'Velocity (m/s)', 'Temp. (°C)', 'Pressure (Kpa)', 'Flow rate (KNm3/h)', 'Opacity (%)', 'Dust (mg/m3)', 'Boiler Eff (%)', 'Entalphy inlet MS (kj/kg)', 'Entropi Inlet MS (Kj/Kg (Deg C))', 'Cold Reheat Pressure (Mpa)', 'Cold Reheat Temperature (°C)', 'Entalphy Cold Reheat (kj/kg)', 'Entalphy Isentropis Cold Reheat (kj/kg)', 'ΔP aktual (Kj/Kg)', 'ΔHP isentropis (Kj/Kg)', 'HP Turbine eff (%)', 'O2 in APH (%)', 'O2 Out APH (%)', 'Refference Temperature (°C)', 'Flue Gas in Temperature (°C)', 'APH Leakage (%)', 'Corrected Flue Gas Out Temperature (°C)', 'APH Effectiveness (%)', 'Coal Flow (t/h)', 'Energy Input From Boiler (Kcal/h)', 'NTHR (Kcal/Kwh)', 'NPHR (Kcal/Kwh)', 'Gross Load (MW)', 'Nett Load (MW)', 'HHV (Kcal/Kg)']\n",
            "Available targets:  ['Main steam flow (t/h)', 'Main steam temperature (boiler side) (℃)', 'Main steam pressure (boiler side) (Mpa)', 'Reheat steam temperature (boiler side) (℃)', 'Superheater desuperheating water flow (t/h)', 'Reheater desuperheating water flow (t/h)', 'Feedwater temperature (℃)', 'Feedwater flow (t/h)', 'Flue gas temperature (℃)', 'Boiler oxygen level (%)', 'Main steam temperature (turbine side) (℃)', 'Main steam pressure (turbine side) (MPa)', 'Reheat steam temperature (turbine side) (℃)', 'Reheat steam pressure (turbine side) (MPa)', 'Control stage pressure (Mpa)', 'High exhaust pressure (Mpa)', 'Feedwater pressure (MPa)', 'Condenser vacuum (kPa)', 'Circulating water outlet temperature (℃)', 'SO2 (mg/m3)', 'Nox (mg/m3)', 'CO (mg/m3)', 'CO2 (ppm)', 'O2 (%)', 'Velocity (m/s)', 'Temp. (°C)', 'Pressure (Kpa)', 'Flow rate (KNm3/h)', 'Opacity (%)', 'Dust (mg/m3)', 'Boiler Eff (%)', 'Entalphy inlet MS (kj/kg)', 'Entropi Inlet MS (Kj/Kg (Deg C))', 'Cold Reheat Pressure (Mpa)', 'Cold Reheat Temperature (°C)', 'Entalphy Cold Reheat (kj/kg)', 'Entalphy Isentropis Cold Reheat (kj/kg)', 'ΔP aktual (Kj/Kg)', 'ΔHP isentropis (Kj/Kg)', 'HP Turbine eff (%)', 'O2 in APH (%)', 'O2 Out APH (%)', 'Refference Temperature (°C)', 'Flue Gas in Temperature (°C)', 'APH Leakage (%)', 'Corrected Flue Gas Out Temperature (°C)', 'APH Effectiveness (%)', 'Coal Flow (t/h)', 'Energy Input From Boiler (Kcal/h)', 'NTHR (Kcal/Kwh)', 'NPHR (Kcal/Kwh)', 'Gross Load (MW)', 'Nett Load (MW)', 'HHV (Kcal/Kg)']\n",
            "Selected features:  ['Main steam flow (t/h)', 'Main steam temperature (boiler side) (℃)', 'Main steam pressure (boiler side) (Mpa)', 'Reheat steam temperature (boiler side) (℃)', 'Superheater desuperheating water flow (t/h)', 'Reheater desuperheating water flow (t/h)', 'Feedwater temperature (℃)', 'Feedwater flow (t/h)', 'Flue gas temperature (℃)', 'Boiler oxygen level (%)', 'Main steam temperature (turbine side) (℃)', 'Main steam pressure (turbine side) (MPa)', 'Reheat steam temperature (turbine side) (℃)', 'Reheat steam pressure (turbine side) (MPa)', 'Control stage pressure (Mpa)', 'High exhaust pressure (Mpa)', 'Feedwater pressure (MPa)', 'Condenser vacuum (kPa)', 'Circulating water outlet temperature (℃)', 'SO2 (mg/m3)', 'Nox (mg/m3)', 'CO (mg/m3)', 'CO2 (ppm)', 'O2 (%)', 'Velocity (m/s)', 'Temp. (°C)', 'Pressure (Kpa)', 'Flow rate (KNm3/h)', 'Opacity (%)', 'Dust (mg/m3)', 'Entalphy inlet MS (kj/kg)', 'Entropi Inlet MS (Kj/Kg (Deg C))', 'Cold Reheat Pressure (Mpa)', 'Cold Reheat Temperature (°C)', 'Entalphy Cold Reheat (kj/kg)', 'Entalphy Isentropis Cold Reheat (kj/kg)', 'ΔP aktual (Kj/Kg)', 'ΔHP isentropis (Kj/Kg)', 'HP Turbine eff (%)', 'O2 in APH (%)', 'O2 Out APH (%)', 'Refference Temperature (°C)', 'Flue Gas in Temperature (°C)', 'APH Leakage (%)', 'Corrected Flue Gas Out Temperature (°C)', 'APH Effectiveness (%)', 'Coal Flow (t/h)', 'Energy Input From Boiler (Kcal/h)', 'NTHR (Kcal/Kwh)', 'NPHR (Kcal/Kwh)', 'Gross Load (MW)', 'Nett Load (MW)', 'HHV (Kcal/Kg)']\n",
            "Selected targets:  ['Boiler Eff (%)']\n",
            "Features and target shape:  (91, 12) (91,)\n",
            "R2 score: 0.99952\n",
            "Decision Tree Train MSE: 0.0000\n",
            "Decision Tree Train MAE: 0.0000\n",
            "Decision Tree Train MAPE: 0.0000\n",
            "Decision Tree Train R²: 1.0000\n",
            "Decision Tree Test MSE: 0.0152\n",
            "Decision Tree Test MAE: 0.0816\n",
            "Decision Tree Test MAPE: 0.0009\n",
            "Decision Tree Test R²: -1.3024\n",
            "Best hyperparameters: {'max_depth': 5, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "Decision Tree Train MSE: 0.0004\n",
            "Decision Tree Test MSE: 0.0034\n",
            "Decision Tree Train R²: 0.9604\n",
            "Decision Tree Test R²: 0.4815\n",
            "Random Forest Train MSE: 0.0005\n",
            "Random Forest Train MAE: 0.0162\n",
            "Random Forest Train MAPE: 0.0002\n",
            "Random Forest Train R²: 0.9497\n",
            "Random Forest Test MSE: 0.0026\n",
            "Random Forest Test MAE: 0.0396\n",
            "Random Forest Test MAPE: 0.0004\n",
            "Random Forest Test R²: 0.6089\n",
            "Random Forest Train MSE: 0.0010\n",
            "Random Forest Train MAE: 0.0202\n",
            "Random Forest Train MAPE: 0.0002\n",
            "Random Forest Train R²: 0.8965\n",
            "Random Forest Test MSE: 0.0026\n",
            "Random Forest Test MAE: 0.0398\n",
            "Random Forest Test MAPE: 0.0004\n",
            "Random Forest Test R²: 0.6118\n",
            "Best hyperparameters: {'max_depth': 7, 'max_features': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Random Forest Train MSE: 0.0012\n",
            "Random Forest Test MSE: 0.0025\n",
            "Random Forest Train R²: 0.8714\n",
            "Random Forest Test R²: 0.6162\n",
            "KNN Train MSE: 0.0037\n",
            "KNN Train MAE: 0.0452\n",
            "KNN Train MAPE: 0.0005\n",
            "KNN Train R²: 0.6193\n",
            "KNN Test MSE: 0.0040\n",
            "KNN Test MAE: 0.0434\n",
            "KNN Test MAPE: 0.0005\n",
            "KNN Test R²: 0.3951\n",
            "Best hyperparameters: {'algorithm': 'auto', 'leaf_size': 20, 'n_neighbors': 3, 'weights': 'distance'}\n",
            "KNN Train MSE: 0.0000\n",
            "KNN Test MSE: 0.0040\n",
            "KNN Train R²: 1.0000\n",
            "KNN Test R²: 0.3913\n"
          ]
        }
      ],
      "source": [
        "!pip install chelo\n",
        "from chelo import DatasetRegistry\n",
        "\n",
        "dataset = DatasetRegistry.get_dataset(\"CoalFiredPlantDataset\")\n",
        "dataset.load_data()\n",
        "X, y = dataset.to_numpy()\n",
        "\n",
        "y = y.ravel()\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "#split data into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "print(f\"Training set size: {X_train.shape[0]}, Test set size: {X_test.shape[0]}\")\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "# Normalize the training data and apply the same scaling to the test data\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "# Fit on training data\n",
        "X_train_normalized = scaler_X.fit_transform(X_train)\n",
        "y_train_normalized = scaler_y.fit_transform(y_train.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Transform test data using the same scaler\n",
        "X_test_normalized = scaler_X.transform(X_test)\n",
        "y_test_normalized = scaler_y.transform(y_test.reshape(-1, 1)).ravel()\n",
        "\n",
        "print(\"min X_train & X_train_normalized: \",np.min(X_train), np.min(X_train_normalized))\n",
        "print(\"max X_train & X_train_normalized: \",np.max(X_train), np.max(X_train_normalized))\n",
        "\n",
        "print(\"min y_train & y_train_normalized: \",np.min(y_train), np.min(y_train_normalized))\n",
        "print(\"max y_train & y_train_normalized: \",np.max(y_train), np.max(y_train_normalized))\n",
        "\n",
        "print(f\"First 2 rows of X_train:\\n{X_train[:2]}\")\n",
        "\n",
        "print(f\"First 2 rows of normalized X_train:\\n{X_train_normalized[:2]}\")\n",
        "\n",
        "print(f\"First 5 values of y_train:\\n{y_train[:5]}\")\n",
        "\n",
        "print(f\"First 5 values of normalized y_train:\\n{y_train_normalized[:5]}\")\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "print(f\"Training set size: {X_train.shape[0]}, Test set size: {X_test.shape[0]}\")\n",
        "\n",
        "print(X_train_normalized.shape, y_train_normalized.shape, X_test_normalized.shape, y_test_normalized.shape)\n",
        "print(f\"Training set size: {X_train_normalized.shape[0]}, Test set size: {X_test_normalized.shape[0]}\")\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "# Train Linear Regression -> train\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_train_normalized, y_train_normalized)\n",
        "\n",
        "# Predict on training data\n",
        "y_train_pred_normalized = linear_model.predict(X_train_normalized).reshape(-1, 1)\n",
        "\n",
        "# Inverse transform the predictions\n",
        "linear_train_predictions = scaler_y.inverse_transform(y_train_pred_normalized).ravel()\n",
        "\n",
        "# Evaluate performance -> train\n",
        "\n",
        "# Calculate MSE - Must use the original (non-normalized) y_train for comparison\n",
        "linear_train_mse = mean_squared_error(y_train, linear_train_predictions)\n",
        "print(f\"Linear Regression Train MSE: {linear_train_mse:.4f}\")\n",
        "\n",
        "# Calculate R2 - Must use the original (non-normalized) y_train for comparison\n",
        "linear_train_r2 = r2_score(y_train, linear_train_predictions)\n",
        "print(f\"Linear Regression Train R2: {linear_train_r2:.4f}\")\n",
        "\n",
        "# Calculate MAE - Must use the original (non-normalized) y_train for comparison\n",
        "linear_train_mae = mean_absolute_error(y_train, linear_train_predictions)\n",
        "print(f\"Linear Regression Train MAE: {linear_train_mae:.4f}\")\n",
        "\n",
        "# Calculate MAPE - Must use the original (non-normalized) y_train for comparison\n",
        "linear_train_mape = mean_absolute_percentage_error(y_train, linear_train_predictions)\n",
        "print(f\"Linear Regression Train MAPE: {linear_train_mape:.4f}\")\n",
        "\n",
        "# Evaluate performance -> test\n",
        "\n",
        "# Predicting using the trained model\n",
        "y_test_pred_normalized = linear_model.predict(X_test_normalized).reshape(-1, 1)\n",
        "\n",
        "# Inverse transform predictions back to original scale\n",
        "linear_test_predictions = scaler_y.inverse_transform(y_test_pred_normalized).ravel()\n",
        "\n",
        "# Calculate evaluation metrics on original scale\n",
        "test_mse = mean_squared_error(y_test, linear_test_predictions)\n",
        "test_r2 = r2_score(y_test, linear_test_predictions)\n",
        "test_mae = mean_absolute_error(y_test, linear_test_predictions)\n",
        "test_mape = mean_absolute_percentage_error(y_test, linear_test_predictions)\n",
        "\n",
        "print(\"\\nTest Set Performance (Original Scale):\")\n",
        "print(f\"Test MSE: {test_mse:.4f}\")\n",
        "print(f\"Test R²: {test_r2:.4f}\")\n",
        "print(f\"Test MAE: {test_mae:.4f}\")\n",
        "print(f\"Test MAPE: {test_mape:.4f}\")\n",
        "\n",
        "print(\"Available features: \", dataset.list_features())\n",
        "print(\"Available targets: \", dataset.list_targets())\n",
        "# Select the first 12 features\n",
        "dataset.select_features(dataset.list_features()[:12])\n",
        "\n",
        "# Extract features (X) and target (y)\n",
        "X, y = dataset.to_numpy()\n",
        "y = y.reshape(-1)\n",
        "\n",
        "# By default, boiler efficiency is only used\n",
        "print(\"Selected features: \", dataset.selected_features())\n",
        "print(\"Selected targets: \", dataset.selected_targets())\n",
        "print(\"Features and target shape: \", X.shape, y.shape)\n",
        "# Initialize the regressor\n",
        "regressor = LinearRegression()\n",
        "\n",
        "# Train the regressor\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = regressor.predict(X_test)\n",
        "print(f\"R2 score: {r2_score(y_test, y_pred):.5f}\")\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Train Decision Tree Regressor -> train\n",
        "tree_model = DecisionTreeRegressor(random_state=42)\n",
        "tree_model.fit(X_train_normalized, y_train_normalized)\n",
        "\n",
        "# Predict on training data\n",
        "y_train_pred_normalized = tree_model.predict(X_train_normalized).reshape(-1, 1)\n",
        "\n",
        "# Inverse transform the predictions\n",
        "tree_train_predictions = scaler_y.inverse_transform(y_train_pred_normalized).ravel()\n",
        "\n",
        "# Evaluate performance -> train\n",
        "\n",
        "# 1. Mean Squared Error (MSE)\n",
        "tree_train_mse = mean_squared_error(y_train, tree_train_predictions)\n",
        "print(f\"Decision Tree Train MSE: {tree_train_mse:.4f}\")\n",
        "\n",
        "# 2. Mean Absolute Error (MAE)\n",
        "tree_train_mae = mean_absolute_error(y_train, tree_train_predictions)\n",
        "print(f\"Decision Tree Train MAE: {tree_train_mae:.4f}\")\n",
        "\n",
        "# 3. Mean Absolute Percentage Error (MAPE)\n",
        "tree_train_mape = mean_absolute_percentage_error(y_train, tree_train_predictions)\n",
        "print(f\"Decision Tree Train MAPE: {tree_train_mape:.4f}\")\n",
        "\n",
        "# 4. R² Score\n",
        "tree_train_r2 = r2_score(y_train, tree_train_predictions)\n",
        "print(f\"Decision Tree Train R²: {tree_train_r2:.4f}\")\n",
        "\n",
        "# Predict on test data\n",
        "y_test_pred_normalized = tree_model.predict(X_test_normalized).reshape(-1, 1)\n",
        "\n",
        "# Inverse transform the predictions for test set\n",
        "tree_test_predictions = scaler_y.inverse_transform(y_test_pred_normalized).ravel()\n",
        "\n",
        "# Evaluate performance -> test\n",
        "\n",
        "# 1. Mean Squared Error (MSE)\n",
        "tree_test_mse = mean_squared_error(y_test, tree_test_predictions)\n",
        "print(f\"Decision Tree Test MSE: {tree_test_mse:.4f}\")\n",
        "\n",
        "# 2. Mean Absolute Error (MAE)\n",
        "tree_test_mae = mean_absolute_error(y_test, tree_test_predictions)\n",
        "print(f\"Decision Tree Test MAE: {tree_test_mae:.4f}\")\n",
        "\n",
        "# 3. Mean Absolute Percentage Error (MAPE)\n",
        "tree_test_mape = mean_absolute_percentage_error(y_test, tree_test_predictions)\n",
        "print(f\"Decision Tree Test MAPE: {tree_test_mape:.4f}\")\n",
        "\n",
        "# 4. R² Score\n",
        "tree_test_r2 = r2_score(y_test, tree_test_predictions)\n",
        "print(f\"Decision Tree Test R²: {tree_test_r2:.4f}\")\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# Define hyperparameter grid for DecisionTreeRegressor\n",
        "param_grid_dt = {\n",
        "    'max_depth': [3, 5, 7, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': [None, 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# GridSearch for DecisionTreeRegressor\n",
        "grid_search_dt = GridSearchCV(DecisionTreeRegressor(random_state=42), param_grid_dt, cv=5, n_jobs=-1)\n",
        "grid_search_dt.fit(X_train_normalized, y_train_normalized)\n",
        "\n",
        "# Best hyperparameters\n",
        "print(f\"Best hyperparameters: {grid_search_dt.best_params_}\")\n",
        "\n",
        "# Train the best model\n",
        "best_dt_model = grid_search_dt.best_estimator_\n",
        "\n",
        "# Predict on training and test data\n",
        "y_train_pred_dt = best_dt_model.predict(X_train_normalized)\n",
        "y_test_pred_dt = best_dt_model.predict(X_test_normalized)\n",
        "\n",
        "# Inverse transform the predictions\n",
        "train_pred_dt = scaler_y.inverse_transform(y_train_pred_dt.reshape(-1, 1)).ravel()\n",
        "test_pred_dt = scaler_y.inverse_transform(y_test_pred_dt.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Evaluate performance on train and test sets\n",
        "train_mse_dt = mean_squared_error(y_train, train_pred_dt)\n",
        "test_mse_dt = mean_squared_error(y_test, test_pred_dt)\n",
        "\n",
        "train_r2_dt = r2_score(y_train, train_pred_dt)\n",
        "test_r2_dt = r2_score(y_test, test_pred_dt)\n",
        "\n",
        "print(f\"Decision Tree Train MSE: {train_mse_dt:.4f}\")\n",
        "print(f\"Decision Tree Test MSE: {test_mse_dt:.4f}\")\n",
        "print(f\"Decision Tree Train R²: {train_r2_dt:.4f}\")\n",
        "print(f\"Decision Tree Test R²: {test_r2_dt:.4f}\")\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Train Random Forest Regressor -> train\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_normalized, y_train_normalized)\n",
        "\n",
        "# Predict on training data\n",
        "y_train_pred_normalized_rf = rf_model.predict(X_train_normalized).reshape(-1, 1)\n",
        "\n",
        "# Inverse transform the predictions for train set\n",
        "rf_train_predictions = scaler_y.inverse_transform(y_train_pred_normalized_rf).ravel()\n",
        "# Evaluate performance -> train\n",
        "\n",
        "# 1. Mean Squared Error (MSE)\n",
        "rf_train_mse = mean_squared_error(y_train, rf_train_predictions)\n",
        "print(f\"Random Forest Train MSE: {rf_train_mse:.4f}\")\n",
        "\n",
        "# 2. Mean Absolute Error (MAE)\n",
        "rf_train_mae = mean_absolute_error(y_train, rf_train_predictions)\n",
        "print(f\"Random Forest Train MAE: {rf_train_mae:.4f}\")\n",
        "\n",
        "# 3. Mean Absolute Percentage Error (MAPE)\n",
        "rf_train_mape = mean_absolute_percentage_error(y_train, rf_train_predictions)\n",
        "print(f\"Random Forest Train MAPE: {rf_train_mape:.4f}\")\n",
        "\n",
        "# 4. R² Score\n",
        "rf_train_r2 = r2_score(y_train, rf_train_predictions)\n",
        "print(f\"Random Forest Train R²: {rf_train_r2:.4f}\")\n",
        "\n",
        "\n",
        "# Predict on test data\n",
        "y_test_pred_normalized_rf = rf_model.predict(X_test_normalized).reshape(-1, 1)\n",
        "\n",
        "# Inverse transform the predictions for test set\n",
        "rf_test_predictions = scaler_y.inverse_transform(y_test_pred_normalized_rf).ravel()\n",
        "\n",
        "# Evaluate performance -> test\n",
        "\n",
        "# 1. Mean Squared Error (MSE)\n",
        "rf_test_mse = mean_squared_error(y_test, rf_test_predictions)\n",
        "print(f\"Random Forest Test MSE: {rf_test_mse:.4f}\")\n",
        "\n",
        "# 2. Mean Absolute Error (MAE)\n",
        "rf_test_mae = mean_absolute_error(y_test, rf_test_predictions)\n",
        "print(f\"Random Forest Test MAE: {rf_test_mae:.4f}\")\n",
        "\n",
        "# 3. Mean Absolute Percentage Error (MAPE)\n",
        "rf_test_mape = mean_absolute_percentage_error(y_test, rf_test_predictions)\n",
        "print(f\"Random Forest Test MAPE: {rf_test_mape:.4f}\")\n",
        "\n",
        "# 4. R² Score\n",
        "rf_test_r2 = r2_score(y_test, rf_test_predictions)\n",
        "print(f\"Random Forest Test R²: {rf_test_r2:.4f}\")\n",
        "\n",
        "# Train Random Forest Regressor -> train\n",
        "rf_model = RandomForestRegressor(n_estimators=50, random_state=42, min_samples_leaf= 3, min_samples_split= 6)\n",
        "rf_model.fit(X_train_normalized, y_train_normalized)\n",
        "\n",
        "# Predict on training data\n",
        "y_train_pred_normalized_rf = rf_model.predict(X_train_normalized).reshape(-1, 1)\n",
        "\n",
        "# Inverse transform the predictions for train set\n",
        "rf_train_predictions = scaler_y.inverse_transform(y_train_pred_normalized_rf).ravel()\n",
        "# Evaluate performance -> train\n",
        "\n",
        "# 1. Mean Squared Error (MSE)\n",
        "rf_train_mse = mean_squared_error(y_train, rf_train_predictions)\n",
        "print(f\"Random Forest Train MSE: {rf_train_mse:.4f}\")\n",
        "\n",
        "# 2. Mean Absolute Error (MAE)\n",
        "rf_train_mae = mean_absolute_error(y_train, rf_train_predictions)\n",
        "print(f\"Random Forest Train MAE: {rf_train_mae:.4f}\")\n",
        "\n",
        "# 3. Mean Absolute Percentage Error (MAPE)\n",
        "rf_train_mape = mean_absolute_percentage_error(y_train, rf_train_predictions)\n",
        "print(f\"Random Forest Train MAPE: {rf_train_mape:.4f}\")\n",
        "\n",
        "# 4. R² Score\n",
        "rf_train_r2 = r2_score(y_train, rf_train_predictions)\n",
        "print(f\"Random Forest Train R²: {rf_train_r2:.4f}\")\n",
        "\n",
        "\n",
        "# Predict on test data\n",
        "y_test_pred_normalized_rf = rf_model.predict(X_test_normalized).reshape(-1, 1)\n",
        "\n",
        "# Inverse transform the predictions for test set\n",
        "rf_test_predictions = scaler_y.inverse_transform(y_test_pred_normalized_rf).ravel()\n",
        "\n",
        "# Evaluate performance -> test\n",
        "\n",
        "# 1. Mean Squared Error (MSE)\n",
        "rf_test_mse = mean_squared_error(y_test, rf_test_predictions)\n",
        "print(f\"Random Forest Test MSE: {rf_test_mse:.4f}\")\n",
        "\n",
        "# 2. Mean Absolute Error (MAE)\n",
        "rf_test_mae = mean_absolute_error(y_test, rf_test_predictions)\n",
        "print(f\"Random Forest Test MAE: {rf_test_mae:.4f}\")\n",
        "\n",
        "# 3. Mean Absolute Percentage Error (MAPE)\n",
        "rf_test_mape = mean_absolute_percentage_error(y_test, rf_test_predictions)\n",
        "print(f\"Random Forest Test MAPE: {rf_test_mape:.4f}\")\n",
        "\n",
        "# 4. R² Score\n",
        "rf_test_r2 = r2_score(y_test, rf_test_predictions)\n",
        "print(f\"Random Forest Test R²: {rf_test_r2:.4f}\")\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define hyperparameter grid for RandomForestRegressor\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [10, 50, 100, 200],\n",
        "    'max_depth': [3, 5, 7, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': [None, 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# GridSearch for RandomForestRegressor\n",
        "grid_search_rf = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_rf, cv=5, n_jobs=-1)\n",
        "grid_search_rf.fit(X_train_normalized, y_train_normalized)\n",
        "\n",
        "# Best hyperparameters\n",
        "print(f\"Best hyperparameters: {grid_search_rf.best_params_}\")\n",
        "\n",
        "# Train the best model\n",
        "best_rf_model = grid_search_rf.best_estimator_\n",
        "\n",
        "# Predict on training and test data\n",
        "y_train_pred_rf = best_rf_model.predict(X_train_normalized)\n",
        "y_test_pred_rf = best_rf_model.predict(X_test_normalized)\n",
        "\n",
        "# Inverse transform the predictions\n",
        "train_pred_rf = scaler_y.inverse_transform(y_train_pred_rf.reshape(-1, 1)).ravel()\n",
        "test_pred_rf = scaler_y.inverse_transform(y_test_pred_rf.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Evaluate performance on train and test sets\n",
        "train_mse_rf = mean_squared_error(y_train, train_pred_rf)\n",
        "test_mse_rf = mean_squared_error(y_test, test_pred_rf)\n",
        "\n",
        "train_r2_rf = r2_score(y_train, train_pred_rf)\n",
        "test_r2_rf = r2_score(y_test, test_pred_rf)\n",
        "\n",
        "print(f\"Random Forest Train MSE: {train_mse_rf:.4f}\")\n",
        "print(f\"Random Forest Test MSE: {test_mse_rf:.4f}\")\n",
        "print(f\"Random Forest Train R²: {train_r2_rf:.4f}\")\n",
        "print(f\"Random Forest Test R²: {test_r2_rf:.4f}\")\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "# Train KNeighbors Regressor -> train\n",
        "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
        "knn_model.fit(X_train_normalized, y_train_normalized)\n",
        "\n",
        "# Predict on training data\n",
        "y_train_pred_normalized_knn = knn_model.predict(X_train_normalized).reshape(-1, 1)\n",
        "\n",
        "# Inverse transform the predictions for train set\n",
        "knn_train_predictions = scaler_y.inverse_transform(y_train_pred_normalized_knn).ravel()\n",
        "\n",
        "# Evaluate performance -> train\n",
        "\n",
        "# 1. Mean Squared Error (MSE)\n",
        "knn_train_mse = mean_squared_error(y_train, knn_train_predictions)\n",
        "print(f\"KNN Train MSE: {knn_train_mse:.4f}\")\n",
        "\n",
        "# 2. Mean Absolute Error (MAE)\n",
        "knn_train_mae = mean_absolute_error(y_train, knn_train_predictions)\n",
        "print(f\"KNN Train MAE: {knn_train_mae:.4f}\")\n",
        "\n",
        "# 3. Mean Absolute Percentage Error (MAPE)\n",
        "knn_train_mape = mean_absolute_percentage_error(y_train, knn_train_predictions)\n",
        "print(f\"KNN Train MAPE: {knn_train_mape:.4f}\")\n",
        "\n",
        "# 4. R² Score\n",
        "knn_train_r2 = r2_score(y_train, knn_train_predictions)\n",
        "print(f\"KNN Train R²: {knn_train_r2:.4f}\")\n",
        "\n",
        "\n",
        "# Predict on test data\n",
        "y_test_pred_normalized_knn = knn_model.predict(X_test_normalized).reshape(-1, 1)\n",
        "\n",
        "# Inverse transform the predictions for test set\n",
        "knn_test_predictions = scaler_y.inverse_transform(y_test_pred_normalized_knn).ravel()\n",
        "\n",
        "# Evaluate performance -> test\n",
        "\n",
        "# 1. Mean Squared Error (MSE)\n",
        "knn_test_mse = mean_squared_error(y_test, knn_test_predictions)\n",
        "print(f\"KNN Test MSE: {knn_test_mse:.4f}\")\n",
        "\n",
        "# 2. Mean Absolute Error (MAE)\n",
        "knn_test_mae = mean_absolute_error(y_test, knn_test_predictions)\n",
        "print(f\"KNN Test MAE: {knn_test_mae:.4f}\")\n",
        "\n",
        "# 3. Mean Absolute Percentage Error (MAPE)\n",
        "knn_test_mape = mean_absolute_percentage_error(y_test, knn_test_predictions)\n",
        "print(f\"KNN Test MAPE: {knn_test_mape:.4f}\")\n",
        "\n",
        "# 4. R² Score\n",
        "knn_test_r2 = r2_score(y_test, knn_test_predictions)\n",
        "print(f\"KNN Test R²: {knn_test_r2:.4f}\")\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define hyperparameter grid for KNeighborsRegressor\n",
        "param_grid_knn = {\n",
        "    'n_neighbors': [3, 5, 10, 20],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
        "    'leaf_size': [20, 30, 40]\n",
        "}\n",
        "\n",
        "# GridSearch for KNeighborsRegressor\n",
        "grid_search_knn = GridSearchCV(KNeighborsRegressor(), param_grid_knn, cv=5, n_jobs=-1)\n",
        "grid_search_knn.fit(X_train_normalized, y_train_normalized)\n",
        "\n",
        "# Best hyperparameters\n",
        "print(f\"Best hyperparameters: {grid_search_knn.best_params_}\")\n",
        "\n",
        "# Train the best model\n",
        "best_knn_model = grid_search_knn.best_estimator_\n",
        "\n",
        "# Predict on training and test data\n",
        "y_train_pred_knn = best_knn_model.predict(X_train_normalized)\n",
        "y_test_pred_knn = best_knn_model.predict(X_test_normalized)\n",
        "\n",
        "# Inverse transform the predictions\n",
        "train_pred_knn = scaler_y.inverse_transform(y_train_pred_knn.reshape(-1, 1)).ravel()\n",
        "test_pred_knn = scaler_y.inverse_transform(y_test_pred_knn.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Evaluate performance on train and test sets\n",
        "train_mse_knn = mean_squared_error(y_train, train_pred_knn)\n",
        "test_mse_knn = mean_squared_error(y_test, test_pred_knn)\n",
        "\n",
        "train_r2_knn = r2_score(y_train, train_pred_knn)\n",
        "test_r2_knn = r2_score(y_test, test_pred_knn)\n",
        "\n",
        "print(f\"KNN Train MSE: {train_mse_knn:.4f}\")\n",
        "print(f\"KNN Test MSE: {test_mse_knn:.4f}\")\n",
        "print(f\"KNN Train R²: {train_r2_knn:.4f}\")\n",
        "print(f\"KNN Test R²: {test_r2_knn:.4f}\")"
      ]
    }
  ]
}